{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aLURyuooJ05"
      },
      "source": [
        "https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb\n",
        "\n",
        "https://www.youtube.com/watch?v=LNwODJXcvt4&list=PLT4ZwFPi5zxFftzI735YoLmq3bFiP2DBo&index=40\n",
        "\n",
        "\n",
        "Todos:\n",
        "* Change the next roboflow dataset to have warriors-home, cavs-away, ball to basketball, rim to hoop, and leave referee\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#from roboflow import Roboflow\n",
        "#rf = Roboflow(api_key=\"htpcxp3XQh7SsgMfjJns\")\n",
        "#project = rf.workspace(\"amrita-hlhw6\").project(\"basketball-and-hoop-detection\")\n",
        "#dataset = project.version(1).download(\"yolov8\")\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"htpcxp3XQh7SsgMfjJns\")\n",
        "project = rf.workspace(\"basketball-formations\").project(\"warriors-vs-cavs-2016\")\n",
        "dataset = project.version(10).download(\"yolov8\")\n",
        "#v5 is only basketball, hoop, referee, and people. warriors/cavs need a lot more images annotated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Note: this notebook requires torch >= 1.10.0\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9hpKL9FZBdc",
        "outputId": "a9fb2206-7c5a-4884-8203-0139df61092a"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from IPython.display import display, Image\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo mode-checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9umkpEsNnRPs"
      },
      "outputs": [],
      "source": [
        "#use to update yaml file train and val to just train/images because the extra hoop-detection is throwing it off\n",
        "\n",
        "import yaml\n",
        "\n",
        "def update_yaml_file(path):\n",
        "    # Load the yaml file\n",
        "    with open(path, 'r') as file:\n",
        "        data_yaml = yaml.safe_load(file)\n",
        "\n",
        "    # Modify the train and validation paths\n",
        "    data_yaml['train'] = 'train/images'\n",
        "    data_yaml['val'] = 'valid/images'\n",
        "\n",
        "    # Save the modified yaml file back\n",
        "    with open(path, 'w') as file:\n",
        "        yaml.dump(data_yaml, file)\n",
        "\n",
        "# Assuming your data.yaml path is /content/Basketball-and-Hoop-Detection-1/data.yaml\n",
        "#update_yaml_file('/content/Basketball-and-Hoop-Detection-1/data.yaml')\n",
        "update_yaml_file('Warriors-vs-Cavs-2016-10\\data.yaml')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Load a model\n",
        "#model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
        "model = YOLO(\"yolov8m.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "data_path = r\"C:\\Users\\ghadf\\vscode_projects\\venv_projects\\Pytorch\\YOLO\\Warriors-vs-Cavs-2016-10\\data.yaml\"\n",
        "# Use the model\n",
        "model.train(data=data_path, epochs=20)  # train the model\n",
        "metrics = model.val()  # evaluate model performance on the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = model(\"https://www.juneauempire.com/wp-content/uploads/2018/08/15282699.jpg\")  # predict on an image\n",
        "path = model.export(format=\"onnx\")  # export the model to ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Track with the model\n",
        "#results = model.track(source=\"https://youtu.be/5zPxyWLls98?si=Bgew802YkfwJOC9T\", show=True)\n",
        "#results = model.track(source=\"https://youtu.be/5zPxyWLls98?si=Bgew802YkfwJOC9T\", show=True, tracker=\"bytetrack.yaml\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGnPkFBoz-ZL",
        "outputId": "1b745908-0af0-40a2-db14-4a5b271d4ba7"
      },
      "outputs": [],
      "source": [
        "#load in data to be inferenced on\n",
        "import yt_dlp\n",
        "\n",
        "# List of YouTube video URLs you want to download\n",
        "video_urls = [\n",
        "    'https://youtu.be/5zPxyWLls98?si=Bgew802YkfwJOC9T'\n",
        "    #'https://www.youtube.com/watch?v=BhVz5eoxpaw'\n",
        "    #,'https://youtu.be/X-N9MEWYN8w'\n",
        "]\n",
        "\n",
        "# Replace with your desired output directory\n",
        "output_path = '/content/Youtube_video/'\n",
        "\n",
        "# Options for yt_dlp (YouTube Downloader)\n",
        "ydl_opts = {\n",
        "    'format': 'best',  # Select the best available format\n",
        "    'outtmpl': output_path + '%(title)s.%(ext)s',  # Output file template\n",
        "    'quiet': True,  # Suppress output messages\n",
        "}\n",
        "\n",
        "# Lists to store successful and failed download URLs\n",
        "failed_downloads = []\n",
        "successful_downloads = []\n",
        "\n",
        "# Initialize YouTube Downloader with the provided options\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    for url in video_urls:\n",
        "        try:\n",
        "            ydl.download([url])  # Download the video\n",
        "            print(\"Downloaded:\", url)\n",
        "            successful_downloads.append(url)\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "            failed_downloads.append(url)\n",
        "\n",
        "# Print results\n",
        "print(\"\\n\" * 4)\n",
        "print(\"Failed downloads:\", failed_downloads)\n",
        "print(\"Successful downloads:\", successful_downloads)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Open the video file\n",
        "video_path = \"content\\Youtube_video\\Stephen Curry hits three straight three-pointers vs. the Grizzlies (2016.04.13).mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Store the track history\n",
        "track_history = defaultdict(lambda: [])\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "        results = model.track(frame, persist=True)\n",
        "\n",
        "        # Get the boxes and track IDs\n",
        "        boxes = results[0].boxes.xywh.cpu()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Plot the tracks\n",
        "        for box, track_id in zip(boxes, track_ids):\n",
        "            x, y, w, h = box\n",
        "            track = track_history[track_id]\n",
        "            track.append((float(x), float(y)))  # x, y center point\n",
        "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
        "                track.pop(0)\n",
        "\n",
        "            # Draw the tracking lines\n",
        "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the display window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the YOLOv8 model\n",
        "#model = YOLO('yolov8n.pt')\n",
        "\n",
        "# Open the video file\n",
        "video_path = video_path\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Loop through the video frames\n",
        "while cap.isOpened():\n",
        "    # Read a frame from the video\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
        "        results = model.track(frame, persist=True)\n",
        "\n",
        "        # Visualize the results on the frame\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # Display the annotated frame\n",
        "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # Break the loop if the end of the video is reached\n",
        "        break\n",
        "\n",
        "# Release the video capture object and close the display window\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import threading\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "def run_tracker_in_thread(filename, model, file_index):\n",
        "    \"\"\"\n",
        "    Runs a video file or webcam stream concurrently with the YOLOv8 model using threading.\n",
        "\n",
        "    This function captures video frames from a given file or camera source and utilizes the YOLOv8 model for object\n",
        "    tracking. The function runs in its own thread for concurrent processing.\n",
        "\n",
        "    Args:\n",
        "        filename (str): The path to the video file or the identifier for the webcam/external camera source.\n",
        "        model (obj): The YOLOv8 model object.\n",
        "        file_index (int): An index to uniquely identify the file being processed, used for display purposes.\n",
        "\n",
        "    Note:\n",
        "        Press 'q' to quit the video display window.\n",
        "    \"\"\"\n",
        "    video = cv2.VideoCapture(filename)  # Read the video file\n",
        "\n",
        "    while True:\n",
        "        ret, frame = video.read()  # Read the video frames\n",
        "\n",
        "        # Exit the loop if no more frames in either video\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Track objects in frames if available\n",
        "        results = model.track(frame, persist=True)\n",
        "        res_plotted = results[0].plot()\n",
        "        cv2.imshow(f\"Tracking_Stream_{file_index}\", res_plotted)\n",
        "\n",
        "        key = cv2.waitKey(1)\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release video sources\n",
        "    video.release()\n",
        "\n",
        "\n",
        "# Load the models\n",
        "model1 = YOLO('yolov8n-seg.pt')\n",
        "model2 = model#YOLO('yolov8n-seg.pt')\n",
        "\n",
        "# Define the video files for the trackers\n",
        "video_file1 = video_path  # Path to video file, 0 for webcam\n",
        "video_file2 = 0  # Path to video file, 0 for webcam, 1 for external camera\n",
        "\n",
        "# Create the tracker threads\n",
        "tracker_thread1 = threading.Thread(target=run_tracker_in_thread, args=(video_file1, model1, 1), daemon=True)\n",
        "tracker_thread2 = threading.Thread(target=run_tracker_in_thread, args=(video_file2, model2, 2), daemon=True)\n",
        "\n",
        "# Start the tracker threads\n",
        "tracker_thread1.start()\n",
        "tracker_thread2.start()\n",
        "\n",
        "# Wait for the tracker threads to finish\n",
        "tracker_thread1.join()\n",
        "tracker_thread2.join()\n",
        "\n",
        "# Clean up and close windows\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
